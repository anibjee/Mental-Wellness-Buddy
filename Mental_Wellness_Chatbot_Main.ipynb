{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain_core langchain_community langchain_groq chromadb scikit-learn streamlit sentence-transformers TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f40aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def initialize_llm():\n",
    "    \n",
    "   llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    api_key=st.secrets[\"GROQ_API_KEY\"],\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    "    ) \n",
    "   return llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db():\n",
    "    # Load all .txt files from subfolders like Text Extracted Files/anxiety, Text Extracted Files/depression, etc.\n",
    "    loader = DirectoryLoader(\n",
    "        \"Text Extracted Files/\",\n",
    "        glob=\"**/*.txt\",           # Recursively `load .txt files`\n",
    "        loader_cls=TextLoader,\n",
    "        use_multithreading=True,\n",
    "        loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Optional: Add category metadata (folder name)\n",
    "    for doc in documents:\n",
    "        folder_name = os.path.basename(os.path.dirname(doc.metadata['source']))\n",
    "        doc.metadata['category'] = folder_name\n",
    "\n",
    "    # Split into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Embed using sentence-transformers\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    # Save to Chroma DB\n",
    "    vector_db = Chroma.from_documents(\n",
    "        texts,\n",
    "        embeddings,\n",
    "        persist_directory='chroma_db'\n",
    "    )\n",
    "    vector_db.persist()\n",
    "\n",
    "    print(\"ChromaDB created and data saved with category-aware metadata\")\n",
    "\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62549233-e708-4af8-9cf5-66432377a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13187c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_qa_chain(vector_db, llm):\n",
    "    \"\"\"Simplified QA chain that uses only vector embeddings for retrieval\"\"\"\n",
    "    # Initialize retriever without category filtering\n",
    "    retriever = vector_db.as_retriever(\n",
    "        search_kwargs={'k': 5}  # Retrieve top 5 most relevant chunks\n",
    "    )\n",
    "\n",
    "    # Enhanced prompt template\n",
    "    prompt_template = \"\"\"You are a compassionate mental health assistant with training in cognitive behavioral therapy and mindfulness techniques. \n",
    "When responding to users:\n",
    "\n",
    "1. FIRST show empathy and validate their feelings\n",
    "2. THEN use the context given below to provide  practical, evidence-based suggestions or solutions to the problem\n",
    "3. FINALLY offer encouragement and next steps\n",
    "\n",
    "Always maintain a warm, supportive tone. If the context doesn't contain specific solutions, draw from established mental health practices.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Problem: {question}\n",
    "\n",
    "Response Structure:\n",
    "[Empathy Statement] Acknowledge their difficulty\n",
    "[Suggestions] Provide actionable steps (use numbered list if multiple)\n",
    "[Encouragement] End with supportive words\n",
    "\n",
    "Example:\n",
    "\"I hear how [specific emotion] this situation is for you. That sounds really challenging. Here are some things that might help:\n",
    "1. [Suggestion 1 - specific action]\n",
    "2. [Suggestion 2 - specific action]\n",
    "Remember that [hopeful statement]. You're taking an important step by reaching out.\"\n",
    "\n",
    "Now respond to this user:\"\"\"\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    # Configure QA chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": PROMPT,\n",
    "            \"document_prompt\": PromptTemplate(\n",
    "                input_variables=[\"page_content\"],\n",
    "                template=\"{page_content}\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db562cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Initializing Mental Wellness Chatbot...\")\n",
    "    llm = initialize_llm()\n",
    "\n",
    "    db_path = \"chroma_db\"\n",
    "    base_data_path = \"Text Extracted Files\"\n",
    "\n",
    "    if not os.path.exists(db_path):\n",
    "        vector_db = create_vector_db()\n",
    "    else:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "        vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "\n",
    "    \n",
    "    # Simplified setup - no category detection needed\n",
    "    qa_chain = setup_qa_chain(vector_db, llm)\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nHuman: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Chatbot: Take care of yourself. Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        # Direct retrieval and generation\n",
    "        result = qa_chain({\"query\": query})\n",
    "        print(f\"Chatbot: {result['result']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7445fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15592a6-912b-4790-9790-2bee9fc10ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
